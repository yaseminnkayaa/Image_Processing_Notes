{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e67754-09df-493a-86b7-27600469b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46929855-5aa5-454b-92f3-f3e64c896512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giriş değerlerinde negatif sayıları sıfırlayarak doğrusal olmayan bir aktivasyon fonksiyonu oluşturuyoruz\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "# ReLU fonksiyonunun türevini hesaplıyoruz. Giriş 0'dan büyükse 1, değilse 0 döndürüyoruz\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "class NeuralMultiplier:\n",
    "    def __init__(self):\n",
    "        # İlk gizli katmanımızda 16, ikinci gizli katmanımızda 8 nöron kullanıyoruz\n",
    "        self.hidden1_size = 16\n",
    "        self.hidden2_size = 8\n",
    "        \n",
    "        # Giriş katmanından ilk gizli katmana giden ağırlıkları Xavier/Glorot yöntemiyle başlatıyoruz\n",
    "        # 2 giriş, hidden1_size kadar çıkış olacak şekilde ağırlık matrisimizi oluşturuyoruz\n",
    "        self.W1 = np.random.randn(2, self.hidden1_size) * np.sqrt(2.0/2)\n",
    "        # İlk gizli katman için bias değerlerimizi sıfır olarak başlatıyoruz\n",
    "        self.b1 = np.zeros((1, self.hidden1_size))\n",
    "        \n",
    "        # İlk gizli katmandan ikinci gizli katmana giden ağırlıkları oluşturuyoruz\n",
    "        self.W2 = np.random.randn(self.hidden1_size, self.hidden2_size) * np.sqrt(2.0/self.hidden1_size)\n",
    "        # İkinci gizli katman için bias değerlerimizi sıfır olarak başlatıyoruz\n",
    "        self.b2 = np.zeros((1, self.hidden2_size))\n",
    "        \n",
    "        # İkinci gizli katmandan çıkış katmanına giden ağırlıkları oluşturuyoruz\n",
    "        self.W3 = np.random.randn(self.hidden2_size, 1) * np.sqrt(2.0/self.hidden2_size)\n",
    "        # Çıkış katmanı için bias değerimizi sıfır olarak başlatıyoruz\n",
    "        self.b3 = np.zeros((1, 1))\n",
    "        \n",
    "        # Ağırlık güncellemelerinde kullanacağımız öğrenme oranını belirliyoruz\n",
    "        self.learning_rate = 0.001\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Giriş değerlerimizi 0-1 aralığına normalize ediyoruz\n",
    "        x1_norm = x1 / 10.0\n",
    "        x2_norm = x2 / 10.0\n",
    "        # Normalize edilmiş girişleri bir matrise dönüştürüyoruz\n",
    "        self.input_layer = np.array([[x1_norm, x2_norm]])\n",
    "        \n",
    "        # İlk gizli katman çıktısını hesaplıyoruz: (giriş x ağırlıklar + bias)'a ReLU uyguluyoruz\n",
    "        self.hidden1 = relu(np.dot(self.input_layer, self.W1) + self.b1)\n",
    "        # İkinci gizli katman çıktısını hesaplıyoruz\n",
    "        self.hidden2 = relu(np.dot(self.hidden1, self.W2) + self.b2)\n",
    "        # Son katmanın çıktısını hesaplıyoruz (burada ReLU kullanmıyoruz)\n",
    "        self.output = np.dot(self.hidden2, self.W3) + self.b3\n",
    "        \n",
    "        # Normalize edilmiş çıktıyı gerçek değer aralığına geri dönüştürüyoruz\n",
    "        return self.output[0, 0] * 100\n",
    "\n",
    "    def backward(self, target, predicted):\n",
    "        # Giriş verisinin batch boyutunu alıyoruz\n",
    "        batch_size = self.input_layer.shape[0]\n",
    "        \n",
    "        # Tahmin ile hedef arasındaki hatayı normalize ediyoruz\n",
    "        error = (predicted - target) / 100\n",
    "\n",
    "        # Gradyan, hatanın en hızlı arttığı yönü gösterir\n",
    "        # Biz ağırlıkları gradyanın tersi yönünde güncelleriz (çünkü hatayı azaltmak istiyoruz)\n",
    "        # Öğrenme oranı bu güncellemenin ne kadar büyük olacağını belirler\n",
    "        \n",
    "        # Çıkış katmanı için gradyanları hesaplıyoruz\n",
    "        d_output = error\n",
    "        # Çıkış katmanı ağırlık gradyanlarını hesaplıyoruz\n",
    "        d_W3 = np.dot(self.hidden2.T, d_output)\n",
    "        # Çıkış katmanı bias gradyanlarını hesaplıyoruz\n",
    "        d_b3 = np.sum(d_output, axis=0, keepdims=True)\n",
    "        \n",
    "        # İkinci gizli katman için gradyanları hesaplıyoruz\n",
    "        d_hidden2 = np.dot(d_output, self.W3.T) * relu_derivative(self.hidden2)\n",
    "        # İkinci gizli katman ağırlık gradyanlarını hesaplıyoruz\n",
    "        d_W2 = np.dot(self.hidden1.T, d_hidden2)\n",
    "        # İkinci gizli katman bias gradyanlarını hesaplıyoruz\n",
    "        d_b2 = np.sum(d_hidden2, axis=0, keepdims=True)\n",
    "        \n",
    "        # İlk gizli katman için gradyanları hesaplıyoruz\n",
    "        d_hidden1 = np.dot(d_hidden2, self.W2.T) * relu_derivative(self.hidden1)\n",
    "        # İlk gizli katman ağırlık gradyanlarını hesaplıyoruz\n",
    "        d_W1 = np.dot(self.input_layer.T, d_hidden1)\n",
    "        # İlk gizli katman bias gradyanlarını hesaplıyoruz\n",
    "        d_b1 = np.sum(d_hidden1, axis=0, keepdims=True)\n",
    "        \n",
    "        # Hesapladığımız gradyanlar ile ağırlık ve bias değerlerini güncelliyoruz\n",
    "        self.W3 -= self.learning_rate * d_W3\n",
    "        self.b3 -= self.learning_rate * d_b3\n",
    "        self.W2 -= self.learning_rate * d_W2\n",
    "        self.b2 -= self.learning_rate * d_b2\n",
    "        self.W1 -= self.learning_rate * d_W1\n",
    "        self.b1 -= self.learning_rate * d_b1\n",
    "\n",
    "    def train(self, epochs=2000):\n",
    "        # Test verilerimizi önceden belirliyoruz ki rastgele sayılar bunlardan oluşmasın\n",
    "        test_pairs = set([(6,7), (3,4), (5,5), (8,2), (9,9)])\n",
    "        \n",
    "        # 500 adet eğitim verisi oluşturuyoruz ama test verilerini dahil etmiyoruz\n",
    "        train_size = 500\n",
    "        train_pairs = []\n",
    "        \n",
    "        while len(train_pairs) < train_size:\n",
    "            # 1-9 arası rastgele iki sayı seçiyoruz\n",
    "            x1 = np.random.randint(1, 10)\n",
    "            x2 = np.random.randint(1, 10)\n",
    "            \n",
    "            # Eğer seçilen sayı çifti test verilerinde yoksa, eğitim verilerine ekleyen kod\n",
    "            if (x1, x2) not in test_pairs:\n",
    "                train_pairs.append([x1, x2])\n",
    "        \n",
    "        # Numpy dizisine çeviriyoruz\n",
    "        X = np.array(train_pairs)\n",
    "        y = X[:, 0] * X[:, 1]  # çarpım sonuçlarını hesaplıyoruz\n",
    "        \n",
    "        best_error = float('inf')\n",
    "        patience = 50\n",
    "        patience_counter = 0\n",
    "        \n",
    "        # Belirlenen epoch sayısı kadar eğitim yapıyoruz\n",
    "        for epoch in range(epochs):\n",
    "            total_error = 0\n",
    "            # Her seferinde 32'lik gruplar halinde eğitim yapıyoruz (mini-batch)\n",
    "            batch_size = 32\n",
    "            for i in range(0, len(X), batch_size):\n",
    "                batch_X = X[i:i+batch_size]\n",
    "                batch_y = y[i:i+batch_size]\n",
    "                \n",
    "                # Her batch içindeki örnekler için ileri ve geri yayılım yapıyoruz\n",
    "                for j in range(len(batch_X)):\n",
    "                    prediction = self.forward(batch_X[j][0], batch_X[j][1])\n",
    "                    total_error += (batch_y[j] - prediction) ** 2\n",
    "                    self.backward(batch_y[j], prediction)\n",
    "            \n",
    "            # Ortalama hatayı hesaplıyoruz\n",
    "            avg_error = total_error / len(X)\n",
    "            \n",
    "            # Early stopping kontrolü yapıyoruz\n",
    "            if avg_error < best_error:\n",
    "                best_error = avg_error\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Belirli bir süre iyileşme olmazsa eğitimi durduruyor\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "            \n",
    "            # Her 100 epoch'ta bir durumu raporluyoruz\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Ortalama Hata: {avg_error:.2f}\")\n",
    "                test_cases = [(2,3), (4,5), (3,7)]\n",
    "                for x1, x2 in test_cases:\n",
    "                    pred = self.forward(x1, x2)\n",
    "                    print(f\"{x1} x {x2} = {pred:.1f} (Gerçek: {x1*x2})\")\n",
    "\n",
    "    # Eğitilmiş modeli kullanarak çarpma işlemi yapıyoruz\n",
    "    def multiply(self, x1, x2):\n",
    "        return self.forward(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3523a2e3-91c8-4cf6-881b-74b4dc0245b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelden bir örnek (instance) oluşturuyoruz ve eğitiyoruz\n",
    "print(\"Eğitim başlıyor...\")\n",
    "multiplier = NeuralMultiplier()\n",
    "multiplier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb17a649-34f7-4688-9263-d49ac9bf40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test verilerimiz ile modelimizin performansını ölçüyoruz.\n",
    "print(\"\\nTest sonuçları:\")\n",
    "test_cases = [(6,7), (3,4), (5,5), (8,2), (9,9)]\n",
    "total_error = 0\n",
    "\n",
    "for a, b in test_cases:\n",
    "    sonuc = multiplier.multiply(a, b)\n",
    "    gercek = a * b\n",
    "    hata = abs(gercek - sonuc)  # Mutlak hata\n",
    "    yuzde_hata = (hata / gercek) * 100  # Yüzde hata\n",
    "    \n",
    "    print(f\"{a} x {b} = {sonuc:.1f} (Gerçek: {gercek}, Hata: {hata:.2f}, Hata Yüzdesi: %{yuzde_hata:.2f})\")\n",
    "    total_error += hata\n",
    "\n",
    "# Ortalama hata hesapla\n",
    "avg_error = total_error / len(test_cases)\n",
    "print(f\"\\nOrtalama Mutlak Hata: {avg_error:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ybs",
   "language": "python",
   "name": "env_ybs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
